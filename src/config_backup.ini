[parameters]

# --- PROGRAM FLOW --- #
human_mode = False
experiments = False

# --- EXPERIMENT PARAMETERS --- #
actor_learning_rates = [0.2, 0.7]
critic_learning_rates = [10.2]
win_multipliers = [50, 100]
initial_epsilons = [0.5, 0.8, 1]
exploitation_thresholds = [0, 1, 2, 3]
# 0: multiplicative decay, 1: linear decay
epsilon_functions = [0]
iterations = 50


# --- ENVIRONMENT CONFIGURATION --- #

# -- TASK 2: 4x4 diamond -- #
action_reward = 0
win_multiplier = 100
win_reward = 1
loss_reward = 0
# 0: triangle, 1: diamond
board_type = 0
board_size = 5
empty_nodes = [(2, 1)]

# -- TASK 3: 4x4 diamond -- #
; action_reward = 0
; win_reward = 1
; loss_reward = 0
; # 0: triangle, 1: diamond
; board_type = 1
; board_size = 4
; empty_nodes = [(3,1)]
; win_multiplier = 100


# --- LEARNING CONFIGURATION --- #
episodes = 600
test_episodes = 10
nn_critic = False
nn_dimentions = (15, 20, 30, 5, 1)
actor_learning_rate = 0.7
critic_learning_rate = 0.7
actor_decay_rate = 0.9
critic_decay_rate = 0.8
actor_discount_factor = 0.95
critic_discount_factor = 0.8


# --- EPSILON CONFIGURATION --- #
linear_epsilon = False
exploitation_threshold = 1
epsilon = 0.8
epsilon_decay = 0.99




visualize = placeholder
# delay between frames in ms
visualization_frame_delay = 100
