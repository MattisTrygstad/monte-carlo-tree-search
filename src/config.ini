[PROGRAM_FLOW]
train = True
tournament = True
human_mode = False
experiments = False

[TOURNAMENT]
tournament_games = 100
visualize = False

[ENVIRONMENT]
board_size = 4

[LEARNING]
episodes = 10
save_interval = 2
epochs = 25
simulations = 1000
nn_dimentions = [64, 64, 64]
# linear, sigmoid, tanh, relu
nn_activation_functions = ['tanh', 'tanh', 'tanh']
# sgd, adam, adagrad or rmsprop
optimizer = 'adam'
actor_learning_rate = 0.01
exploration_constant = 1

[EPSILON]
epsilon = 0.1

[VISUALIZATION]
visualization_delay = 0.5
