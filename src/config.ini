[PROGRAM_FLOW]
human_mode = True
experiments = False

[EXPERIMENT]


[ENVIRONMENT]
win_multiplier = 100
reinforcement = 1

board_size = 4
filled_nodes = []

[LEARNING]
rollout_bias = 0.3
exploitation_factor = 0.2
simulations = 100
episodes = 100
save_interval = 50
epochs = 20
nn_dimentions = [50, 16]
nn_activation_functions = ['relu', 'relu']
critic_learning_rate = 0.7
actor_learning_rate = 0.8

[EPSILON]
epsilon = 0.8
epsilon_decay = 0.985
linear_epsilon = False
exploitation_threshold = 1

[VISUALIZATION]
visualize_without_convergence = True
visualization_delay = 0.5
