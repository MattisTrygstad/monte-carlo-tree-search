[PROGRAM_FLOW]
online_tournament = True
train = False
tournament = True

[TOURNAMENT]
tournament_games = 100
visualize = False

[ENVIRONMENT]
board_size = 6

[LEARNING]
episodes = 500
save_interval = 25
epochs = 1
simulations = 500
nn_dimentions = [64, 64, 64]
# linear, sigmoid, tanh, relu
nn_activation_functions = ['relu', 'relu', 'relu']
# sgd, adam, adagrad or rmsprop
optimizer = 'adam'
actor_learning_rate = 0.001
exploration_constant = 1.4
sample_size = 512
buffer_limit = 10000
model_dir = 'oht_2'

[EPSILON]
epsilon = 0.4

[VISUALIZATION]
visualization_delay = 0.5