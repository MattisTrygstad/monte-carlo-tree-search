[PROGRAM_FLOW]
train = False
tournament = True
human_mode = False
experiments = False


[TOURNAMENT]
tournament_games = 100


[ENVIRONMENT]
board_size = 4
reinforcement = 1

[LEARNING]
episodes = 100
epochs = 25
simulations = 500
nn_dimentions = [128, 128, 128, 128]
# linear, sigmoid, tanh, relu
nn_activation_functions = ['relu', 'relu', 'relu', 'relu']
# sgd, adam, adagrad or rmsprop
optimizer = 'adam'
actor_learning_rate = 0.0005
critic_learning_rate = 0.7
save_interval = 20
exploration_constant = 1
rollout_bias = 0.3

[EPSILON]
epsilon = 0.1
epsilon_decay = 0.985

[VISUALIZATION]
visualization_delay = 0.5
